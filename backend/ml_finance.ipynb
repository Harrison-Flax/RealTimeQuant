{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad859ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Daily Cleveland CPI-nowcast model:\n",
    "- Builds a daily dataset from Cleveland \"Table View\" CSVs (one file per month).\n",
    "- Merges FRED daily/weekly features (Brent, Gas, Claims), forward-filling sparse series.\n",
    "- Predicts next-day change in nowcast (Δ), avoiding lookahead.\n",
    "Requires: pandas, numpy, scikit-learn, requests\n",
    "Env: FRED_API_KEY must be set for FRED JSON API (falls back to fredgraph.csv if missing).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    fred_api_key: Optional[str] = os.getenv(\"FRED_API_KEY\")  # set in your env for authenticated pulls\n",
    "    cleveland_src_dir: str = \"/Users/eddiekayizzi/Downloads/RealTimeQuant/backend/data\"                  # folder with monthly \"Table View\" CSVs\n",
    "    out_dir: str = \"artifacts_daily\"\n",
    "    start_date: str = \"2020-01-01\"                           # adjust if you have older Cleveland files\n",
    "    end_date: str = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "FRED_OBS_API = \"https://api.stlouisfed.org/fred/series/observations\"\n",
    "FREDGRAPH_CSV = \"https://fred.stlouisfed.org/graph/fredgraph.csv\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# FRED loader (API first, CSV fallback)\n",
    "# ----------------------------\n",
    "\n",
    "def fred_series(series_id: str, start: str, end: str, api_key: Optional[str]) -> pd.DataFrame:\n",
    "    # Why: prefer API; fallback keeps dev flow if key missing.\n",
    "    if api_key:\n",
    "        params = {\"series_id\": series_id, \"file_type\": \"json\",\n",
    "                  \"observation_start\": start, \"observation_end\": end,\n",
    "                  \"api_key\": api_key}\n",
    "        try:\n",
    "            r = requests.get(FRED_OBS_API, params=params, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            payload = r.json()\n",
    "            obs = payload.get(\"observations\", [])\n",
    "            df = pd.DataFrame(obs)\n",
    "            if not df.empty:\n",
    "                df = df.loc[:, [\"date\", \"value\"]]\n",
    "                df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "                df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "                df = df.dropna().sort_values(\"date\").set_index(\"date\")\n",
    "                df.columns = [series_id]\n",
    "                return df\n",
    "            warnings.warn(f\"FRED API returned no rows for {series_id}; using csv fallback.\")\n",
    "        except requests.HTTPError as e:\n",
    "            warnings.warn(f\"FRED API error for {series_id}: {e}; using csv fallback.\")\n",
    "\n",
    "    r = requests.get(FREDGRAPH_CSV, params={\"id\": series_id}, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    raw = pd.read_csv(io.StringIO(r.text))\n",
    "    if \"observation_date\" not in raw.columns or series_id not in raw.columns:\n",
    "        raise ValueError(f\"Unexpected fredgraph format for {series_id}\")\n",
    "    raw[\"observation_date\"] = pd.to_datetime(raw[\"observation_date\"], errors=\"coerce\")\n",
    "    raw[series_id] = pd.to_numeric(raw[series_id], errors=\"coerce\")\n",
    "    mask = (raw[\"observation_date\"] >= pd.to_datetime(start)) & (raw[\"observation_date\"] <= pd.to_datetime(end))\n",
    "    df = raw.loc[mask, [\"observation_date\", series_id]].dropna().sort_values(\"observation_date\")\n",
    "    return df.set_index(\"observation_date\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Cleveland daily nowcast loader (directory of monthly CSVs)\n",
    "# ----------------------------\n",
    "\n",
    "def _infer_year_month_from_name(path: str) -> Optional[Tuple[int, int]]:\n",
    "    m = re.search(r\"(20\\d{2})[-_ ]?(\\d{1,2})\", os.path.basename(path))\n",
    "    if not m:\n",
    "        return None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def _pick_cpi_column(cols: List[str]) -> Optional[str]:\n",
    "    for c in cols:\n",
    "        lc = str(c).lower().replace(\" \", \"\")\n",
    "        if \"cpi\" in lc and \"core\" not in lc:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _parse_cleveland_month_csv(path: str) -> Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Failed to read {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    label_col = next((c for c in df.columns if str(c).strip().lower() in {\"label\", \"date\"}), None)\n",
    "    if not label_col:\n",
    "        warnings.warn(f\"No 'Label' column in {path}\")\n",
    "        return None\n",
    "    cpi_col = _pick_cpi_column(list(df.columns))\n",
    "    if not cpi_col:\n",
    "        warnings.warn(f\"No CPI MoM col in {path}\")\n",
    "        return None\n",
    "\n",
    "    ym = _infer_year_month_from_name(path)\n",
    "    if not ym:\n",
    "        warnings.warn(f\"Cannot infer YYYY-MM from {path}\")\n",
    "        return None\n",
    "    year, month = ym\n",
    "\n",
    "    def to_dt(s: str):\n",
    "        s = str(s).strip()\n",
    "        if not s or s.lower() == \"nan\":\n",
    "            return None\n",
    "        try:\n",
    "            mm, dd = s.split(\"/\")\n",
    "            return datetime(year=year, month=int(mm), day=int(dd))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    df[\"date\"] = df[label_col].apply(to_dt)\n",
    "    df = df.dropna(subset=[\"date\"]).sort_values(\"date\")\n",
    "    df[\"cpi_mom_nowcast\"] = pd.to_numeric(df[cpi_col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"cpi_mom_nowcast\"])\n",
    "    out = df[[\"date\", \"cpi_mom_nowcast\"]].copy()\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"])\n",
    "    return out.set_index(\"date\")\n",
    "\n",
    "def load_cleveland_daily(src_dir: str) -> pd.DataFrame:\n",
    "    files = sorted(glob.glob(os.path.join(src_dir, \"*.csv\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No Cleveland CSV files in {src_dir}\")\n",
    "    parts = []\n",
    "    for f in files:\n",
    "        d = _parse_cleveland_month_csv(f)\n",
    "        if d is not None and not d.empty:\n",
    "            parts.append(d)\n",
    "    if not parts:\n",
    "        raise RuntimeError(\"No usable Cleveland files parsed.\")\n",
    "    df = pd.concat(parts).sort_index()\n",
    "    # Deduplicate dates (keep last)\n",
    "    df = df[~df.index.duplicated(keep=\"last\")]\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Daily feature table\n",
    "# ----------------------------\n",
    "\n",
    "def daily_log_return(series: pd.Series) -> pd.Series:\n",
    "    return 100.0 * np.log(series / series.shift(1))\n",
    "\n",
    "def build_daily_dataset() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Target (daily nowcast)\n",
    "    nc = load_cleveland_daily(CFG.cleveland_src_dir)\n",
    "    # Expand to full daily calendar, ffill gaps (weekends missing in Cleveland on some months)\n",
    "    calendar = pd.date_range(max(pd.to_datetime(CFG.start_date), nc.index.min()),\n",
    "                             min(pd.to_datetime(CFG.end_date), nc.index.max()),\n",
    "                             freq=\"D\")\n",
    "    nc = nc.reindex(calendar).ffill()\n",
    "\n",
    "    # FRED features\n",
    "    brent = fred_series(\"DCOILBRENTEU\", calendar.min().strftime(\"%Y-%m-%d\"),\n",
    "                        calendar.max().strftime(\"%Y-%m-%d\"), CFG.fred_api_key).rename(columns={\"DCOILBRENTEU\": \"brent\"})\n",
    "    gas = fred_series(\"GASREGW\", calendar.min().strftime(\"%Y-%m-%d\"),\n",
    "                      calendar.max().strftime(\"%Y-%m-%d\"), CFG.fred_api_key).rename(columns={\"GASREGW\": \"gas\"})\n",
    "    claims = fred_series(\"IC4WSA\", calendar.min().strftime(\"%Y-%m-%d\"),\n",
    "                         calendar.max().strftime(\"%Y-%m-%d\"), CFG.fred_api_key).rename(columns={\"IC4WSA\": \"claims4w\"})\n",
    "\n",
    "    # Reindex each to daily calendar & ffill (why: weekends/weekly cadence)\n",
    "    # \"reindex(calendar)\" aligns the brent DataFrame to the daily 'calendar' date range.\n",
    "    # This expands brent to have a row for every day in 'calendar', even if brent originally only included, for example, business days or some weekly frequency from FRED.\n",
    "    # Any missing dates (e.g., weekends, holidays) are filled with NaN, which are then forward-filled by .ffill().\n",
    "    # This ensures brent has daily values matching the date index used for all other features,\n",
    "    # so that feature engineering, rolling windows, and eventual model training all work day-by-day.\n",
    "    brent = brent.reindex(calendar).ffill()\n",
    "    gas = gas.reindex(calendar).ffill()\n",
    "    claims = claims.reindex(calendar).ffill()\n",
    "\n",
    "    # Feature engineering (lag everything to avoid lookahead)\n",
    "    feats = pd.DataFrame(index=calendar)\n",
    "    feats[\"nc\"] = nc[\"cpi_mom_nowcast\"]\n",
    "    feats[\"nc_lag1\"] = feats[\"nc\"].shift(1)\n",
    "    feats[\"nc_lag3\"] = feats[\"nc\"].shift(3)\n",
    "    feats[\"nc_lag7\"] = feats[\"nc\"].shift(7)\n",
    "    feats[\"nc_ma7\"] = feats[\"nc\"].rolling(7, min_periods=3).mean()\n",
    "    feats[\"nc_std7\"] = feats[\"nc\"].rolling(7, min_periods=3).std()\n",
    "    feats[\"nc_ma14\"] = feats[\"nc\"].rolling(14, min_periods=5).mean()\n",
    "\n",
    "    feats[\"brent\"] = brent[\"brent\"]\n",
    "    feats[\"brent_ret\"] = daily_log_return(feats[\"brent\"]).shift(1)   # lag 1\n",
    "    feats[\"brent_ret_3\"] = feats[\"brent_ret\"].rolling(3, min_periods=1).sum()\n",
    "    feats[\"brent_ret_7\"] = feats[\"brent_ret\"].rolling(7, min_periods=3).sum()\n",
    "\n",
    "    feats[\"gas\"] = gas[\"gas\"]\n",
    "    feats[\"gas_ret\"] = daily_log_return(feats[\"gas\"]).shift(1)\n",
    "    feats[\"gas_ret_7\"] = feats[\"gas_ret\"].rolling(7, min_periods=3).sum()\n",
    "\n",
    "    # Claims: weekly level + weekly change (computed on weekly series then ffilled)\n",
    "    claims_weekly_change = claims[\"claims4w\"].diff().where(claims.index.dayofweek == claims.index.dayofweek)  # placeholder calc\n",
    "    feats[\"claims4w\"] = claims[\"claims4w\"].shift(1)  # lag 1 day\n",
    "    feats[\"claims_chg\"] = claims[\"claims4w\"].diff()\n",
    "\n",
    "    # Calendar features (position within month)\n",
    "    dom = feats.index.day\n",
    "    month_len = feats.index.daysinmonth\n",
    "    feats[\"dom_sin\"] = np.sin(2 * np.pi * dom / month_len)\n",
    "    feats[\"dom_cos\"] = np.cos(2 * np.pi * dom / month_len)\n",
    "\n",
    "    # Target: next-day change in nowcast (Δ)\n",
    "    y = feats[\"nc\"].shift(-1) - feats[\"nc\"]\n",
    "\n",
    "    # Final cleanup\n",
    "    X = feats.drop(columns=[\"nc\"])  # we keep lags/rolls, not the contemporaneous 'nc'\n",
    "    df = pd.concat([X, y.rename(\"y_next_delta\")], axis=1).dropna()\n",
    "    return df.drop(columns=[\"brent\", \"gas\"]), nc  # drop raw price levels to keep it lean\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Modeling (walk-forward)\n",
    "# ----------------------------\n",
    "\n",
    "def train_eval_daily(df: pd.DataFrame) -> Dict:\n",
    "    Xcols = [c for c in df.columns if c != \"y_next_delta\"]\n",
    "    ycol = \"y_next_delta\"\n",
    "    X, y = df[Xcols], df[ycol]\n",
    "\n",
    "    pre = ColumnTransformer([(\"num\", StandardScaler(), Xcols)], remainder=\"drop\")\n",
    "    enet = Pipeline([(\"pre\", pre),\n",
    "                     (\"m\", ElasticNet(alpha=0.02, l1_ratio=0.15, max_iter=5000, random_state=42))])\n",
    "    gbr = Pipeline([(\"pre\", pre),\n",
    "                    (\"m\", GradientBoostingRegressor(random_state=42, n_estimators=600, max_depth=3, learning_rate=0.03))])\n",
    "\n",
    "    # Use smaller k if dataset is short\n",
    "    n_splits = min(8, max(3, len(X) // 40))\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    enet_mae, enet_rmse, gbr_mae, gbr_rmse = [], [], [], []\n",
    "    for tr, te in tscv.split(X):\n",
    "        Xtr, Xte, ytr, yte = X.iloc[tr], X.iloc[te], y.iloc[tr], y.iloc[te]\n",
    "        enet.fit(Xtr, ytr); p1 = enet.predict(Xte)\n",
    "        gbr.fit(Xtr, ytr);  p2 = gbr.predict(Xte)\n",
    "        enet_mae.append(mean_absolute_error(yte, p1))\n",
    "        enet_rmse.append(math.sqrt(mean_squared_error(yte, p1)))\n",
    "        gbr_mae.append(mean_absolute_error(yte, p2))\n",
    "        gbr_rmse.append(math.sqrt(mean_squared_error(yte, p2)))\n",
    "\n",
    "    metrics = {\n",
    "        \"avg_enet_mae\": float(np.mean(enet_mae)),\n",
    "        \"avg_enet_rmse\": float(np.mean(enet_rmse)),\n",
    "        \"avg_gbr_mae\": float(np.mean(gbr_mae)),\n",
    "        \"avg_gbr_rmse\": float(np.mean(gbr_rmse)),\n",
    "        \"splits\": n_splits,\n",
    "        \"rows\": int(len(X)),\n",
    "        \"start\": X.index.min().strftime(\"%Y-%m-%d\"),\n",
    "        \"end\": X.index.max().strftime(\"%Y-%m-%d\"),\n",
    "    }\n",
    "\n",
    "    # Fit on all and forecast tomorrow (Δ and level)\n",
    "    enet.fit(X, y)\n",
    "    gbr.fit(X, y)\n",
    "    x_last = X.iloc[[-1]]\n",
    "    delta_pred = float(gbr.predict(x_last)[0])\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"latest\": {\n",
    "            \"asof\": X.index.max().strftime(\"%Y-%m-%d\"),\n",
    "            \"delta_pred\": delta_pred,\n",
    "            # Level forecast for tomorrow = today_nowcast + delta_pred\n",
    "            \"level_pred\": float(df.loc[X.index.max(), \"y_next_delta\"] + df.loc[X.index.max(), \"y_next_delta\"].shift(1) if False else np.nan)  # placeholder\n",
    "        },\n",
    "        \"models\": {\"enet\": enet, \"gbr\": gbr}\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b5b478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Utilities to interpret your daily-nowcast model and forecast future days.\n",
    "\n",
    "Drop this into the same environment where you ran the daily model.\n",
    "Assumptions:\n",
    "- You already built `daily_df` (features + y) and `nc` (Cleveland nowcast series).\n",
    "- You already have `models` from training: {'enet': enet_pipeline, 'gbr': gbr_pipeline}.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, Tuple\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "\n",
    "# --- 2) Diagnostics -------------------------------------------------------\n",
    "\n",
    "def model_diagnostics(daily_df: pd.DataFrame, preds_gbr: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare model MAE/RMSE vs a naive baseline (predict Δ=0), and report drift.\n",
    "    \"\"\"\n",
    "    y = daily_df[\"y_next_delta\"].values\n",
    "    naive = np.zeros_like(y)  # Δ=0 baseline\n",
    "    return {\n",
    "        \"naive_mae\": float(mean_absolute_error(y, naive)),\n",
    "        \"naive_rmse\": float(math.sqrt(mean_squared_error(y, naive))),\n",
    "        \"model_mae\": float(mean_absolute_error(y, preds_gbr)),\n",
    "        \"model_rmse\": float(math.sqrt(mean_squared_error(y, preds_gbr))),\n",
    "        \"improvement_mae\": float(mean_absolute_error(y, naive) - mean_absolute_error(y, preds_gbr)),\n",
    "        \"improvement_rmse\": float(math.sqrt(mean_squared_error(y, naive)) - math.sqrt(mean_squared_error(y, preds_gbr))),\n",
    "    }\n",
    "\n",
    "def gbr_feature_importance(gbr_pipeline, feature_names: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract relative importances from GradientBoosting inside the pipeline.\n",
    "    \"\"\"\n",
    "    gb = gbr_pipeline.named_steps[\"m\"]\n",
    "    importances = getattr(gb, \"feature_importances_\", None)\n",
    "    if importances is None:\n",
    "        return pd.DataFrame(columns=[\"feature\", \"importance\"])\n",
    "    imp = (\n",
    "        pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "        .sort_values(\"importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return imp\n",
    "\n",
    "# --- 3) Forecasts ---------------------------------------------------------\n",
    "\n",
    "def predict_tomorrow(daily_df: pd.DataFrame,\n",
    "                     nc: pd.DataFrame,\n",
    "                     models: Dict[str, object]) -> Dict:\n",
    "    \"\"\"\n",
    "    Predict tomorrow's Δ(nowcast) and level using the last available feature row.\n",
    "    \"\"\"\n",
    "    Xcols = [c for c in daily_df.columns if c != \"y_next_delta\"]\n",
    "    X = daily_df[Xcols]\n",
    "    last_idx = X.index.max()\n",
    "    x_last = X.loc[[last_idx]]\n",
    "    delta_pred = float(models[\"gbr\"].predict(x_last)[0])\n",
    "    today_level = float(nc.loc[last_idx, \"cpi_mom_nowcast\"])\n",
    "    return {\n",
    "        \"asof\": str(last_idx.date()),\n",
    "        \"delta_pred\": delta_pred,\n",
    "        \"level_today\": today_level,\n",
    "        \"level_tomorrow_pred\": today_level + delta_pred,\n",
    "    }\n",
    "\n",
    "def _apply_hold_last(exog_future: pd.DataFrame, last_row: pd.Series, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    When user doesn't provide exogenous future (brent_ret, gas_ret, claims...), hold last values.\n",
    "    \"\"\"\n",
    "    out = exog_future.copy()\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            out[c] = last_row[c]\n",
    "        out[c] = out[c].fillna(method=\"ffill\").fillna(last_row[c])\n",
    "    return out\n",
    "\n",
    "def forecast_path(daily_df: pd.DataFrame,\n",
    "                  nc: pd.DataFrame,\n",
    "                  models: Dict[str, object],\n",
    "                  days: int = 5,\n",
    "                  exog_future: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Multi-step simulation for the next `days` trading/calendar days.\n",
    "\n",
    "    exog_future (optional): DataFrame indexed by future dates with any of:\n",
    "      ['brent_ret','brent_ret_3','brent_ret_7','gas_ret','gas_ret_7','claims4w','claims_chg','dom_sin','dom_cos']\n",
    "    Missing columns are forward-filled using the last observed values.\n",
    "    \"\"\"\n",
    "    Xcols = [c for c in daily_df.columns if c != \"y_next_delta\"]\n",
    "    hist = daily_df.copy()\n",
    "    model = models[\"gbr\"]\n",
    "\n",
    "    # Seed with the last known day\n",
    "    last_date = hist.index.max()\n",
    "    future_idx = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=days, freq=\"D\")\n",
    "\n",
    "    # Build a template of future rows by repeating the last row\n",
    "    last_row = hist.iloc[-1].copy()\n",
    "    fut = pd.DataFrame([last_row.values] * days, columns=hist.columns, index=future_idx)\n",
    "\n",
    "    # Recompute calendar features for future days\n",
    "    fut[\"dom_sin\"] = np.sin(2 * np.pi * fut.index.day / fut.index.daysinmonth)\n",
    "    fut[\"dom_cos\"] = np.cos(2 * np.pi * fut.index.day / fut.index.daysinmonth)\n",
    "\n",
    "    # If the caller provided future exogenous paths, blend them in; else hold last values\n",
    "    exog_cols = [\"brent_ret\",\"brent_ret_3\",\"brent_ret_7\",\"gas_ret\",\"gas_ret_7\",\"claims4w\",\"claims_chg\"]\n",
    "    if exog_future is not None and not exog_future.empty:\n",
    "        exog_future = exog_future.reindex(future_idx)\n",
    "        fut[exog_cols] = _apply_hold_last(exog_future, last_row, exog_cols)[exog_cols]\n",
    "    else:\n",
    "        # nothing provided → keep last values\n",
    "        pass\n",
    "\n",
    "    # Simulate forward: update lags and moving averaging windows each step\n",
    "    outputs = []\n",
    "    current_nc = float(nc.loc[last_date, \"cpi_mom_nowcast\"])\n",
    "\n",
    "    for dt in future_idx:\n",
    "        # Use current history for lagged features\n",
    "        # lags of 'nc'\n",
    "        last_nc_series = pd.Series([np.nan,], index=[dt])  # placeholder to keep shape\n",
    "        # recompute lag/rolling using the accumulating forecast path:\n",
    "        # We need nc_lag1/3/7, ma7, std7, ma14 from the evolving nc series.\n",
    "        # Build a temporary NC series combining historical nc with simulated levels so far.\n",
    "        tmp_nc = nc[\"cpi_mom_nowcast\"].copy()\n",
    "        if outputs:\n",
    "            sim_index = [o[\"date\"] for o in outputs]\n",
    "            sim_levels = [o[\"level\"] for o in outputs]\n",
    "            tmp_nc = pd.concat([tmp_nc, pd.Series(sim_levels, index=sim_index)])\n",
    "        tmp_nc = tmp_nc.sort_index()\n",
    "\n",
    "        # compute lags/rolls as of 'dt-1'\n",
    "        lag1  = tmp_nc.shift(1).loc[dt]\n",
    "        lag3  = tmp_nc.shift(3).loc[dt]\n",
    "        lag7  = tmp_nc.shift(7).loc[dt]\n",
    "        ma7   = tmp_nc.rolling(7, min_periods=3).mean().shift(0).loc[dt]\n",
    "        std7  = tmp_nc.rolling(7, min_periods=3).std().shift(0).loc[dt]\n",
    "        ma14  = tmp_nc.rolling(14, min_periods=5).mean().shift(0).loc[dt]\n",
    "\n",
    "        fut.loc[dt, [\"nc_lag1\",\"nc_lag3\",\"nc_lag7\",\"nc_ma7\",\"nc_std7\",\"nc_ma14\"]] = [lag1, lag3, lag7, ma7, std7, ma14]\n",
    "\n",
    "        # Build X row and predict Δ\n",
    "        x_row = fut.loc[[dt], Xcols]\n",
    "        delta = float(model.predict(x_row)[0])\n",
    "        current_nc = current_nc + delta  # level_t+1\n",
    "        outputs.append({\"date\": dt, \"delta\": delta, \"level\": current_nc})\n",
    "\n",
    "    out = pd.DataFrame(outputs).set_index(\"date\")\n",
    "    return out\n",
    "\n",
    "# --- 4) Quick how-to ------------------------------------------------------\n",
    "\n",
    "def quick_usage_example(daily_df, nc, models):\n",
    "    \"\"\"\n",
    "    Example of using the helpers in a notebook:\n",
    "    \"\"\"\n",
    "    # 1) Tomorrow\n",
    "    tmr = predict_tomorrow(daily_df, nc, models)\n",
    "    print(\"Tomorrow forecast:\", tmr)\n",
    "\n",
    "    # 2) 5-day hold-last simulation\n",
    "    path = forecast_path(daily_df, nc, models, days=5)\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a98c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data] rows=670 range=2024-01-12→2025-11-11 features=15\n",
      "{\n",
      "  \"avg_enet_mae\": 0.024680838270393756,\n",
      "  \"avg_enet_rmse\": 0.052469487369654066,\n",
      "  \"avg_gbr_mae\": 0.044793303067085316,\n",
      "  \"avg_gbr_rmse\": 0.07287466004187598,\n",
      "  \"splits\": 8,\n",
      "  \"rows\": 670,\n",
      "  \"start\": \"2024-01-12\",\n",
      "  \"end\": \"2025-11-11\"\n",
      "}\n",
      "Latest forecast: {\n",
      "  \"asof\": \"2025-11-11\",\n",
      "  \"delta_pred\": -0.06989717042166743,\n",
      "  \"level_pred\": 0.22656075178820156\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Orchestrator\n",
    "# ----------------------------\n",
    "\n",
    "def run() -> None:\n",
    "    os.makedirs(CFG.out_dir, exist_ok=True)\n",
    "    daily_df, nc = build_daily_dataset()\n",
    "    print(f\"[data] rows={len(daily_df)} range={daily_df.index.min().date()}→{daily_df.index.max().date()} features={len(daily_df.columns)-1}\")\n",
    "    result = train_eval_daily(daily_df)\n",
    "\n",
    "    # Compute tomorrow's level forecast properly\n",
    "    last_date = daily_df.index.max()\n",
    "    today_nowcast = float(nc.loc[last_date, \"cpi_mom_nowcast\"])\n",
    "    delta_pred = result[\"latest\"][\"delta_pred\"]\n",
    "    result[\"latest\"][\"level_pred\"] = today_nowcast + delta_pred\n",
    "\n",
    "    # Save\n",
    "    with open(os.path.join(CFG.out_dir, \"daily_metrics.json\"), \"w\") as f:\n",
    "        json.dump(result[\"metrics\"], f, indent=2)\n",
    "    with open(os.path.join(CFG.out_dir, \"daily_latest.json\"), \"w\") as f:\n",
    "        json.dump(result[\"latest\"], f, indent=2)\n",
    "\n",
    "    print(json.dumps(result[\"metrics\"], indent=2))\n",
    "    print(\"Latest forecast:\", json.dumps(result[\"latest\"], indent=2))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf845c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data] rows=670 range=2024-01-12→2025-11-11 features=15\n",
      "[metrics] {'avg_enet_mae': 0.024680838270393756, 'avg_enet_rmse': 0.052469487369654066, 'avg_gbr_mae': 0.044793303067085316, 'avg_gbr_rmse': 0.07287466004187598, 'splits': 8, 'rows': 670, 'start': '2024-01-12', 'end': '2025-11-11'}\n",
      "{'naive_mae': 0.018029366872091654, 'naive_rmse': 0.05647548412204237, 'model_mae': 0.010915146389023833, 'model_rmse': 0.022089272362885604, 'improvement_mae': 0.007114220483067821, 'improvement_rmse': 0.034386211759156765}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nc_std7</td>\n",
       "      <td>0.137062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nc_ma14</td>\n",
       "      <td>0.135722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nc_ma7</td>\n",
       "      <td>0.119212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brent_ret_7</td>\n",
       "      <td>0.116482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nc_lag1</td>\n",
       "      <td>0.098819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>brent_ret_3</td>\n",
       "      <td>0.093956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gas_ret</td>\n",
       "      <td>0.071586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dom_sin</td>\n",
       "      <td>0.049698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dom_cos</td>\n",
       "      <td>0.040493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>brent_ret</td>\n",
       "      <td>0.039494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0      nc_std7    0.137062\n",
       "1      nc_ma14    0.135722\n",
       "2       nc_ma7    0.119212\n",
       "3  brent_ret_7    0.116482\n",
       "4      nc_lag1    0.098819\n",
       "5  brent_ret_3    0.093956\n",
       "6      gas_ret    0.071586\n",
       "7      dom_sin    0.049698\n",
       "8      dom_cos    0.040493\n",
       "9    brent_ret    0.039494"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asof': '2025-11-11', 'delta_pred': -0.06989717042166743, 'level_today': 0.296457922209869, 'level_tomorrow_pred': 0.22656075178820156}\n"
     ]
    }
   ],
   "source": [
    "# Build data & train\n",
    "daily_df, nc = build_daily_dataset()\n",
    "res = train_eval_daily(daily_df)\n",
    "models = res[\"models\"]\n",
    "metrics = res[\"metrics\"]\n",
    "\n",
    "print(f\"[data] rows={len(daily_df)} range={daily_df.index.min().date()}→{daily_df.index.max().date()} features={len(daily_df.columns)-1}\")\n",
    "print(\"[metrics]\", metrics)\n",
    "\n",
    "# 2) Diagnostics — compare to naive Δ=0\n",
    "Xcols = [c for c in daily_df.columns if c != \"y_next_delta\"]\n",
    "preds_gbr_in_sample = models[\"gbr\"].predict(daily_df[Xcols])\n",
    "print(model_diagnostics(daily_df, preds_gbr_in_sample))\n",
    "\n",
    "# 3) Feature importance (what moved the model)\n",
    "imp = gbr_feature_importance(models[\"gbr\"], Xcols)\n",
    "display(imp.head(10))\n",
    "\n",
    "# 4) Predict tomorrow\n",
    "print(predict_tomorrow(daily_df, nc, models))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2a8138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nowcast(\n",
    "    # Required: Current nowcast level and historical values\n",
    "    current_nowcast: float,\n",
    "    nowcast_lag1: float,      # Yesterday's nowcast\n",
    "    nowcast_lag3: float,      # 3 days ago\n",
    "    nowcast_lag7: float,       # 7 days ago\n",
    "    nowcast_ma7: float,        # 7-day moving average\n",
    "    nowcast_std7: float,       # 7-day standard deviation\n",
    "    nowcast_ma14: float,      # 14-day moving average\n",
    "    \n",
    "    # Required: Economic indicators\n",
    "    brent_ret: float,         # Brent oil daily return (%)\n",
    "    brent_ret_3: float,       # 3-day sum of Brent returns\n",
    "    brent_ret_7: float,       # 7-day sum of Brent returns\n",
    "    gas_ret: float,           # Gas daily return (%)\n",
    "    gas_ret_7: float,         # 7-day sum of gas returns\n",
    "    claims4w: float,          # 4-week initial claims\n",
    "    claims_chg: float,        # Change in claims\n",
    "    \n",
    "    # Required: Date for calendar features\n",
    "    date: str,                # Format: \"YYYY-MM-DD\"\n",
    "    \n",
    "    # Optional: Trained model (if None, will use the last trained model)\n",
    "    model=None,\n",
    "    \n",
    "    # Optional: Return format\n",
    "    return_level: bool = True  # If True, returns level_tomorrow_pred, else just delta\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Predict tomorrow's CPI nowcast change and level.\n",
    "    \n",
    "    Args:\n",
    "        current_nowcast: Today's Cleveland CPI MoM nowcast value\n",
    "        nowcast_lag1/3/7: Historical nowcast values (1, 3, 7 days ago)\n",
    "        nowcast_ma7/ma14: Moving averages of nowcast\n",
    "        nowcast_std7: Standard deviation of nowcast over 7 days\n",
    "        brent_ret: Brent oil daily return (%)\n",
    "        brent_ret_3/7: Sum of Brent returns over 3/7 days\n",
    "        gas_ret: Gas daily return (%)\n",
    "        gas_ret_7: Sum of gas returns over 7 days\n",
    "        claims4w: 4-week initial claims value\n",
    "        claims_chg: Change in claims\n",
    "        date: Date string in \"YYYY-MM-DD\" format\n",
    "        model: Trained model (GradientBoostingRegressor pipeline). If None, uses global model.\n",
    "        return_level: If True, returns predicted level for tomorrow, else just delta\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with prediction results:\n",
    "        {\n",
    "            'asof': date,\n",
    "            'delta_pred': predicted change in nowcast,\n",
    "            'level_today': current nowcast level,\n",
    "            'level_tomorrow_pred': predicted nowcast for tomorrow (if return_level=True)\n",
    "        }\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Use provided model or get from global scope\n",
    "    if model is None:\n",
    "        # Try to get from global scope (assumes model was trained in same session)\n",
    "        if 'models' not in globals():\n",
    "            raise ValueError(\"No model provided and no trained model found. Train model first or pass model parameter.\")\n",
    "        model = globals()['models']['gbr']\n",
    "    \n",
    "    # Calculate calendar features\n",
    "    dt = pd.to_datetime(date)\n",
    "    dom = dt.day\n",
    "    month_len = dt.daysinmonth\n",
    "    dom_sin = np.sin(2 * np.pi * dom / month_len)\n",
    "    dom_cos = np.cos(2 * np.pi * dom / month_len)\n",
    "    \n",
    "    # Build feature vector in the same order as training\n",
    "    features = {\n",
    "        'nc_lag1': nowcast_lag1,\n",
    "        'nc_lag3': nowcast_lag3,\n",
    "        'nc_lag7': nowcast_lag7,\n",
    "        'nc_ma7': nowcast_ma7,\n",
    "        'nc_std7': nowcast_std7,\n",
    "        'nc_ma14': nowcast_ma14,\n",
    "        'brent_ret': brent_ret,\n",
    "        'brent_ret_3': brent_ret_3,\n",
    "        'brent_ret_7': brent_ret_7,\n",
    "        'gas_ret': gas_ret,\n",
    "        'gas_ret_7': gas_ret_7,\n",
    "        'claims4w': claims4w,\n",
    "        'claims_chg': claims_chg,\n",
    "        'dom_sin': dom_sin,\n",
    "        'dom_cos': dom_cos,\n",
    "    }\n",
    "    \n",
    "    # Convert to DataFrame (model expects DataFrame format)\n",
    "    feature_df = pd.DataFrame([features], index=[dt])\n",
    "    \n",
    "    # Make prediction\n",
    "    delta_pred = float(model.predict(feature_df)[0])\n",
    "    \n",
    "    # Build result\n",
    "    result = {\n",
    "        'asof': date,\n",
    "        'delta_pred': delta_pred,\n",
    "        'level_today': current_nowcast,\n",
    "    }\n",
    "    \n",
    "    if return_level:\n",
    "        result['level_tomorrow_pred'] = current_nowcast + delta_pred\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Alternative: Simplified version that accepts a dictionary\n",
    "def predict_nowcast_from_dict(features_dict: dict, model=None, return_level: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Simplified version that accepts all features as a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        features_dict: Dictionary with all required features:\n",
    "            {\n",
    "                'current_nowcast': float,\n",
    "                'nowcast_lag1': float,\n",
    "                'nowcast_lag3': float,\n",
    "                'nowcast_lag7': float,\n",
    "                'nowcast_ma7': float,\n",
    "                'nowcast_std7': float,\n",
    "                'nowcast_ma14': float,\n",
    "                'brent_ret': float,\n",
    "                'brent_ret_3': float,\n",
    "                'brent_ret_7': float,\n",
    "                'gas_ret': float,\n",
    "                'gas_ret_7': float,\n",
    "                'claims4w': float,\n",
    "                'claims_chg': float,\n",
    "                'date': 'YYYY-MM-DD'\n",
    "            }\n",
    "        model: Trained model (optional)\n",
    "        return_level: If True, returns predicted level for tomorrow\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with prediction results\n",
    "    \"\"\"\n",
    "    return predict_nowcast(\n",
    "        current_nowcast=features_dict['current_nowcast'],\n",
    "        nowcast_lag1=features_dict['nowcast_lag1'],\n",
    "        nowcast_lag3=features_dict['nowcast_lag3'],\n",
    "        nowcast_lag7=features_dict['nowcast_lag7'],\n",
    "        nowcast_ma7=features_dict['nowcast_ma7'],\n",
    "        nowcast_std7=features_dict['nowcast_std7'],\n",
    "        nowcast_ma14=features_dict['nowcast_ma14'],\n",
    "        brent_ret=features_dict['brent_ret'],\n",
    "        brent_ret_3=features_dict['brent_ret_3'],\n",
    "        brent_ret_7=features_dict['brent_ret_7'],\n",
    "        gas_ret=features_dict['gas_ret'],\n",
    "        gas_ret_7=features_dict['gas_ret_7'],\n",
    "        claims4w=features_dict['claims4w'],\n",
    "        claims_chg=features_dict['claims_chg'],\n",
    "        date=features_dict['date'],\n",
    "        model=model,\n",
    "        return_level=return_level\n",
    "    )\n",
    "\n",
    "\n",
    "# Helper function to extract features from the latest row of daily_df\n",
    "def get_latest_features_for_prediction(daily_df: pd.DataFrame, nc: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the latest feature values from daily_df to use for prediction.\n",
    "    This is useful for getting current values to pass to predict_nowcast.\n",
    "    \n",
    "    Args:\n",
    "        daily_df: The daily dataset DataFrame\n",
    "        nc: The Cleveland nowcast DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with all features needed for prediction\n",
    "    \"\"\"\n",
    "    last_date = daily_df.index.max()\n",
    "    last_row = daily_df.iloc[-1]\n",
    "    current_nowcast = float(nc.loc[last_date, 'cpi_mom_nowcast'])\n",
    "    \n",
    "    return {\n",
    "        'current_nowcast': current_nowcast,\n",
    "        'nowcast_lag1': float(last_row['nc_lag1']),\n",
    "        'nowcast_lag3': float(last_row['nc_lag3']),\n",
    "        'nowcast_lag7': float(last_row['nc_lag7']),\n",
    "        'nowcast_ma7': float(last_row['nc_ma7']),\n",
    "        'nowcast_std7': float(last_row['nc_std7']),\n",
    "        'nowcast_ma14': float(last_row['nc_ma14']),\n",
    "        'brent_ret': float(last_row['brent_ret']),\n",
    "        'brent_ret_3': float(last_row['brent_ret_3']),\n",
    "        'brent_ret_7': float(last_row['brent_ret_7']),\n",
    "        'gas_ret': float(last_row['gas_ret']),\n",
    "        'gas_ret_7': float(last_row['gas_ret_7']),\n",
    "        'claims4w': float(last_row['claims4w']),\n",
    "        'claims_chg': float(last_row['claims_chg']),\n",
    "        'date': str(last_date.date())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54b26079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asof': '2025-11-11', 'delta_pred': -0.06989717042166743, 'level_today': 0.296457922209869, 'level_tomorrow_pred': 0.22656075178820156}\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Using the function with dynamic values from your data\n",
    "# Get the latest features from your actual dataset\n",
    "latest_features = get_latest_features_for_prediction(daily_df, nc)\n",
    "\n",
    "# Use those dynamic values for prediction\n",
    "prediction = predict_nowcast(\n",
    "    current_nowcast=latest_features['current_nowcast'],\n",
    "    nowcast_lag1=latest_features['nowcast_lag1'],\n",
    "    nowcast_lag3=latest_features['nowcast_lag3'],\n",
    "    nowcast_lag7=latest_features['nowcast_lag7'],\n",
    "    nowcast_ma7=latest_features['nowcast_ma7'],\n",
    "    nowcast_std7=latest_features['nowcast_std7'],\n",
    "    nowcast_ma14=latest_features['nowcast_ma14'],\n",
    "    brent_ret=latest_features['brent_ret'],\n",
    "    brent_ret_3=latest_features['brent_ret_3'],\n",
    "    brent_ret_7=latest_features['brent_ret_7'],\n",
    "    gas_ret=latest_features['gas_ret'],\n",
    "    gas_ret_7=latest_features['gas_ret_7'],\n",
    "    claims4w=latest_features['claims4w'],\n",
    "    claims_chg=latest_features['claims_chg'],\n",
    "    date=latest_features['date'],\n",
    "    model=models['gbr']  # or None to use global model\n",
    ")\n",
    "\n",
    "\n",
    "# Example 2: Using dictionary input (easier for API/frontend) - with dynamic values\n",
    "# Extract latest features from your actual data\n",
    "latest_features = get_latest_features_for_prediction(daily_df, nc)\n",
    "\n",
    "# Use the dictionary directly\n",
    "prediction = predict_nowcast_from_dict(latest_features, model=models['gbr'])\n",
    "\n",
    "\n",
    "# Example 3: Alternative - Extract values directly from DataFrames\n",
    "# Get the last row from daily_df and corresponding nowcast value\n",
    "last_date = daily_df.index.max()\n",
    "last_row = daily_df.iloc[-1]\n",
    "current_nowcast = float(nc.loc[last_date, 'cpi_mom_nowcast'])\n",
    "\n",
    "# Build features dictionary directly from DataFrames\n",
    "features = {\n",
    "    'current_nowcast': current_nowcast,\n",
    "    'nowcast_lag1': float(last_row['nc_lag1']),\n",
    "    'nowcast_lag3': float(last_row['nc_lag3']),\n",
    "    'nowcast_lag7': float(last_row['nc_lag7']),\n",
    "    'nowcast_ma7': float(last_row['nc_ma7']),\n",
    "    'nowcast_std7': float(last_row['nc_std7']),\n",
    "    'nowcast_ma14': float(last_row['nc_ma14']),\n",
    "    'brent_ret': float(last_row['brent_ret']),\n",
    "    'brent_ret_3': float(last_row['brent_ret_3']),\n",
    "    'brent_ret_7': float(last_row['brent_ret_7']),\n",
    "    'gas_ret': float(last_row['gas_ret']),\n",
    "    'gas_ret_7': float(last_row['gas_ret_7']),\n",
    "    'claims4w': float(last_row['claims4w']),\n",
    "    'claims_chg': float(last_row['claims_chg']),\n",
    "    'date': str(last_date.date())\n",
    "}\n",
    "\n",
    "prediction = predict_nowcast_from_dict(features, model=models['gbr'])\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
